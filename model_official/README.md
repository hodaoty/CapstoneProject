1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng
CÃ i dependencies:
pip install -r requirements.txt


YÃªu cáº§u cÃ¡c thÆ° viá»‡n chÃ­nh:

scikit-learn

LightGBM

pandas

scipy

rich

Cáº¥u trÃºc thÆ° má»¥c:

project/
â”‚â”€â”€ src/
â”‚    â”œâ”€â”€ preprocess_clean.py
â”‚    â”œâ”€â”€ train_clean.py
â”‚    â”œâ”€â”€ infer_clean.py
â”‚    â”œâ”€â”€ utils_clean.py
â”‚â”€â”€ data/
â”‚    â”œâ”€â”€ bai.csv
â”‚    â”œâ”€â”€ SQL.csv
â”‚    â”œâ”€â”€ XSS.csv
â”‚    â”œâ”€â”€ commmand.csv
â”‚    â”œâ”€â”€ *optional: SQL_new.csv / XSS_new.csv / CMD_new.csv*
â”‚â”€â”€ dataset/
â”‚â”€â”€ models/

ğŸ— 2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
Script: preprocess_clean.py
(Ä‘Ã£ nÃ¢ng cáº¥p â€” chuáº©n hÃ³a text, decode nhiá»u lá»›p, sinh meta-feature nÃ¢ng cao)

Cháº¡y:

python src/preprocess_clean.py


Script sáº½:

Load dataset trong thÆ° má»¥c data/

Map láº¡i cÃ¡c nhÃ£n (XSS=2, CMD=3â€¦)

Chuáº©n hÃ³a URL + BODY (multi-decode, HTML unescape)

Extract hÆ¡n 20 meta-features

Shuffle dá»¯ liá»‡u

LÆ°u file chuáº©n hÃ³a:

dataset/train_df_clean.parquet


Káº¿t quáº£ ká»³ vá»ng:

âœ” Dataset saved â†’ dataset/train_df_clean.parquet
ğŸ“Š Shape: (XXXX, 26)
ğŸ“Œ Label counts:
0: ...
1: ...
2: ...
3: ...


ğŸ“Œ File tham chiáº¿u: preprocess_clean.py 

preprocess_clean

ğŸ¤– 3. Train mÃ´ hÃ¬nh LightGBM

Script: train_clean.py

Cháº¡y:

python src/train_clean.py


Script sáº½:

Load dataset parquet

TF-IDF vectorize (char-level 2â€“6gram)

Merge meta-features â†’ sparse matrix

TÃ¡ch: train (64%) / validation (16%) / test (20%)

Huáº¥n luyá»‡n LightGBM vá»›i early-stopping

Ãnh xáº¡ nhÃ£n â†’ {0: Benign, 1: SQL, 2: XSS, 3: CMD}

LÆ°u model:

models/model_clean.pkl


Káº¿t quáº£ hiá»ƒn thá»‹:

Classification report

Confusion matrix

Loss giáº£m theo epoch

ğŸ“Œ File tham chiáº¿u: train_clean.py 

train_clean

ğŸ” 4. Kiá»ƒm thá»­ payload (CLI Tester)

Script: infer_clean.py

Cháº¡y:

python src/infer_clean.py


TÃ­nh nÄƒng:

Load model + TF-IDF

Giao diá»‡n terminal Ä‘áº¹p báº±ng Rich

Test tá»« file CSV payload:

payloads/benign.csv

payloads/sqli.csv

payloads/xss.csv

payloads/command.csv

Sáº¯p xáº¿p theo Ä‘á»™ nguy hiá»ƒm

Hiá»ƒn thá»‹: label, confidence, probability, payload

VÃ­ dá»¥:

========== PAYLOAD TESTER ==========
1. Test Benign
2. Test SQL Injection
3. Test XSS
4. Test Command Injection
5. ThoÃ¡t
====================================


ğŸ“Œ File tham chiáº¿u: infer_clean.py 

infer_clean

ğŸ›  5. MÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tháº¿ nÃ o?

Model sá»­ dá»¥ng 2 nguá»“n tÃ­n hiá»‡u:

âœ” TF-IDF character-level

Báº¯t cÃ¡c pattern:

' or 1=1 --

<script>

; ls -la

../../etc/passwd

Bypass encode (%27%27%3b)

âœ” Meta-features (ráº¥t quan trá»ng)

VÃ­ dá»¥:

entropy, base64_chunk_count â†’ detect encode/bypass

xss_event_count, rare_tag_count â†’ detect XSS khÃ³

cmd_special_count, shell_pattern_count â†’ detect command injection

sql_logic_count, sql_boolean_ops â†’ detect SQL logic-based

ğŸ“Œ File chá»©c nÄƒng: utils_clean.py 

utils_clean

ğŸ§ª 6. TÃ­ch há»£p vÃ o Microservice

Model Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ nhÃºng vÃ o kiáº¿n trÃºc:

Client â†’ API Gateway â†’ Security Model (SQL/XSS/CMD) â†’ Microservices


Báº¡n chá»‰ cáº§n:

Load model tá»« models/model_clean.pkl

Gá»i hÃ m predict_url(url, body)

Náº¿u output â‰  Benign â†’ block / log / alert

ğŸ¯ 7. Lá»‡nh tÃ³m táº¯t
âœ” Tiá»n xá»­ lÃ½
python src/preprocess_clean.py

âœ” Train model
python src/train_clean.py

âœ” Test payload
python src/infer_clean.py